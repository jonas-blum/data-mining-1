{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2be546c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Sepal Length:  -5.705507692307693\n",
      "Standard Deviation Sepal Length:  303.7889483450795\n"
     ]
    }
   ],
   "source": [
    "# TASK 1: reading the data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "data = pd.read_csv(\"iris_data.csv\", delimiter=\";\")\n",
    "labels = pd.read_csv(\"iris_labels.csv\", delimiter=\";\")\n",
    "\n",
    "data = pd.merge(data , labels , on=\"id\", how=\"inner\")\n",
    "data.drop([\"examiner\"], axis=1, inplace=True)\n",
    "data = data.sort_values(\"species\")\n",
    "\n",
    "\n",
    "\n",
    "# What are the average length of sepals (sl) and their standard deviation?\n",
    "print(\"Average Sepal Length: \", data[\"sl\"].mean())\n",
    "print(\"Standard Deviation Sepal Length: \", data[\"sl\"].std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0252f550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "species\n",
      "Iris-setosa        3000\n",
      "Iris-virginica     3000\n",
      "Iris-versicolor     500\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# TASK 2: database preprocessing\n",
    "\n",
    "# How many instances are there for each class?\n",
    "print(data[\"species\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "26f85987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If the system doesn't know which values are missing, the missing values are interpreted as valid values which might lead to wrong results.\n",
      "Average Sepal Length:  3.5275947028025865\n",
      "Standard Deviation Sepal Length:  2.102492233385377\n",
      "Shape of data before removing outliers:  (6494, 6)\n",
      "Average Sepal Length:  3.5206258671188535\n",
      "Standard Deviation Sepal Length:  2.0185052102580663\n",
      "Shape of data after removing outliers:  (6487, 4)\n"
     ]
    }
   ],
   "source": [
    "# TASK 3: data cleaning\n",
    "\n",
    "# Why is it important to let the system know which values are missing?\n",
    "print(\"If the system doesn't know which values are missing, the missing values are interpreted as valid values which might lead to wrong results.\")\n",
    "\n",
    "data = data[data[\"pl\"] != -9999]\n",
    "data = data[data[\"pw\"] != -9999]\n",
    "data = data[data[\"sl\"] != -9999]\n",
    "data = data[data[\"sw\"] != -9999]\n",
    "\n",
    "# 3.1 What are the average length of sepals (sl) and their standard deviation after declaring missing values\n",
    "print(\"Average Sepal Length: \", data[\"sl\"].mean())\n",
    "print(\"Standard Deviation Sepal Length: \", data[\"sl\"].std())\n",
    "\n",
    "# 3.2 What are the average length of sepals (sl) and their standard deviation after removing outliers\n",
    "print(\"Shape of data before removing outliers: \", data.shape)\n",
    "numerical_features = data[['pl', 'pw', 'sl', 'sw']]\n",
    "threshold = 3\n",
    "z_scores = np.abs(stats.zscore(numerical_features))\n",
    "numerical_features = numerical_features[(z_scores < threshold).all(axis=1)]\n",
    "print(\"Average Sepal Length: \", numerical_features[\"sl\"].mean())\n",
    "print(\"Standard Deviation Sepal Length: \", numerical_features[\"sl\"].std())\n",
    "print(\"Shape of data after removing outliers: \", numerical_features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7544c380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min-Max Normalized Sepal Length Mean:  0.4388106237288472\n",
      "Min-Max Normalized Sepal Length Standard Deviation:  0.32554026184977275\n",
      "Standardized Sepal Length Mean:  -2.1030400071826612e-16\n",
      "Standardized Sepal Length Standard Deviation:  1.0\n",
      "Explained variance per feature:\n",
      "[0.94006639 0.04067178 0.01390087 0.00536096]\n",
      "Cumulative explained variance:\n",
      "[0.94006639 0.98073817 0.99463904 1.        ]\n",
      "Variance captured by the first two components:  0.9807381701533205\n",
      "First principal component as a combination of the original attributes: \n",
      " [ 0.35625159 -0.07970588  0.85674407  0.36430945]\n",
      "Explained variance per feature for modified dataset:\n",
      "[9.99853047e-01 1.30371448e-04 1.23909054e-05 4.19097813e-06]\n",
      "Cumulative explained variance for modified dataset:\n",
      "[0.99985305 0.99998342 0.99999581 1.        ]\n",
      "Explained variance per feature for modified dataset with outlier:\n",
      "[9.98690855e-01 1.25935344e-03 3.79044326e-05 1.18874454e-05]\n",
      "Cumulative explained variance for modified dataset with outlier:\n",
      "[0.99869085 0.99995021 0.99998811 1.        ]\n"
     ]
    }
   ],
   "source": [
    "# TASK 4: data transformation\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# What are the average length and standard deviation of sepals after min-max normalization?\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "minmax_scaled = MinMaxScaler().fit_transform(numerical_features)\n",
    "print(\"Min-Max Normalized Sepal Length Mean: \", minmax_scaled[:,2].mean())\n",
    "print(\"Min-Max Normalized Sepal Length Standard Deviation: \", minmax_scaled[:,2].std())\n",
    "\n",
    "# What are the average length and standard deviation of sepals after standardization?\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sd_scaled = StandardScaler().fit_transform(numerical_features)\n",
    "print(\"Standardized Sepal Length Mean: \", sd_scaled[:,2].mean())\n",
    "print(\"Standardized Sepal Length Standard Deviation: \", sd_scaled[:,2].std())\n",
    "\n",
    "# How many components have been selected after 4.3?\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "principal_components = pca.fit_transform(numerical_features)\n",
    "print(\"Explained variance per feature:\")\n",
    "print(pca.explained_variance_ratio_)\n",
    "# cummulative explained variance\n",
    "cumulative_explained_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "print(\"Cumulative explained variance:\")\n",
    "print(cumulative_explained_variance)\n",
    "# How much variance is captured by the first two components?\n",
    "print(\"Variance captured by the first two components: \", pca.explained_variance_ratio_[0] + pca.explained_variance_ratio_[1])\n",
    "\n",
    "# How is the first component defined as a combination of the original attributes?\n",
    "print(\"First principal component as a combination of the original attributes: \\n\", pca.components_[0])\n",
    "\n",
    "# How many components would have been selected after 4.4 (that is, with an attribute expressed on a larger range)?\n",
    "\n",
    "modified_dataset = numerical_features.copy()\n",
    "modified_dataset['pl'] = modified_dataset['pl'] * 100.0\n",
    "modified_principal_components = pca.fit_transform(modified_dataset)\n",
    "print(\"Explained variance per feature for modified dataset:\")\n",
    "print(pca.explained_variance_ratio_)\n",
    "# Cummulative explained variance\n",
    "cumulative_explained_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "print(\"Cumulative explained variance for modified dataset:\")\n",
    "print(cumulative_explained_variance)\n",
    "\n",
    "# How many components would have been selected after 4.5 (that is, with an outlier)?\n",
    "modified_dataset = numerical_features.copy()\n",
    "modified_dataset.at[0, \"pl\" ] = 5000.0\n",
    "modified_principal_components = pca.fit_transform(modified_dataset)\n",
    "print(\"Explained variance per feature for modified dataset with outlier:\")\n",
    "print(pca.explained_variance_ratio_)\n",
    "# Cummulative explained variance\n",
    "cumulative_explained_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "print(\"Cumulative explained variance for modified dataset with outlier:\")\n",
    "print(cumulative_explained_variance)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7755e99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Task 5.1:\n",
      "(150, 6)\n",
      "species\n",
      "Iris-setosa        72\n",
      "Iris-virginica     66\n",
      "Iris-versicolor    12\n",
      "Name: count, dtype: int64\n",
      "Unique samples:  150\n",
      "\n",
      "Task 5.2:\n",
      "(150, 6)\n",
      "species\n",
      "Iris-setosa        69\n",
      "Iris-virginica     69\n",
      "Iris-versicolor    12\n",
      "Name: count, dtype: int64\n",
      "Unique samples:  150\n",
      "\n",
      "Task 5.3:\n",
      "(3247, 6)\n",
      "species\n",
      "Iris-virginica     1499\n",
      "Iris-setosa        1498\n",
      "Iris-versicolor     250\n",
      "Name: count, dtype: int64\n",
      "Unique samples:  3247\n",
      "\n",
      "Task 5.4:\n",
      "(150, 6)\n",
      "species\n",
      "Iris-setosa        50\n",
      "Iris-versicolor    50\n",
      "Iris-virginica     50\n",
      "Name: count, dtype: int64\n",
      "Unique samples:  150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w7/3sh8mbdx6p30vgwkwwz5p0vh0000gp/T/ipykernel_40867/668443839.py:21: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sample3 = data.groupby(\"species\", group_keys=False).apply(\n",
      "/var/folders/w7/3sh8mbdx6p30vgwkwwz5p0vh0000gp/T/ipykernel_40867/668443839.py:29: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sample4 = data.groupby(\"species\", group_keys=False).apply(\n"
     ]
    }
   ],
   "source": [
    "# TASK 5:\n",
    "\n",
    "random_state = 42\n",
    "\n",
    "# 5.1\n",
    "print(\"\\nTask 5.1:\")\n",
    "sample1 = data.sample(n=150, random_state=random_state)\n",
    "print(sample1.shape)\n",
    "print(sample1[\"species\"].value_counts())\n",
    "print(\"Unique samples: \", sample1[\"id\"].nunique())\n",
    "\n",
    "# 5.2\n",
    "print(\"\\nTask 5.2:\")\n",
    "sample2 = data.sample(n=150, random_state=random_state, replace=True)\n",
    "print(sample2.shape)\n",
    "print(sample2[\"species\"].value_counts())\n",
    "print(\"Unique samples: \",sample2[\"id\"].nunique())\n",
    "\n",
    "# 5.3\n",
    "print(\"\\nTask 5.3:\")\n",
    "sample3 = data.groupby(\"species\", group_keys=False).apply(\n",
    "lambda x: x.sample(frac=0.5, random_state=random_state))\n",
    "print(sample3.shape)\n",
    "print(sample3[\"species\"].value_counts())\n",
    "print(\"Unique samples: \",sample3[\"id\"].nunique())\n",
    "\n",
    "# 5.4\n",
    "print(\"\\nTask 5.4:\")\n",
    "sample4 = data.groupby(\"species\", group_keys=False).apply(\n",
    "lambda x: x.sample(50, random_state=random_state))\n",
    "print(sample4.shape)\n",
    "print(sample4[\"species\"].value_counts())\n",
    "print(\"Unique samples: \",sample4[\"id\"].nunique())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
