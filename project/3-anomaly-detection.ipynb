{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2d338fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.neighbors import NearestNeighbors, LocalOutlierFactor\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.decomposition import PCA\n",
    "from collections import Counter\n",
    "from sklearn.cluster import MiniBatchKMeans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9ceaf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3749891, 13)\n",
      "                                             EntryID  \\\n",
      "0  e/ed12adf025b5491da54c4ff2c8c5377a/c/c2dbc8151...   \n",
      "1  e/7f6fb13b5a99449bb9dcbb3f8693be73/c/7477fb677...   \n",
      "2  e/624ca9226b6526ebdb69f9b46df482c7/c/32c6bf5bc...   \n",
      "3  e/2fdf59e075094fe1847137af34eda0f7/c/eb22afe81...   \n",
      "4  e/4d8de05f989d43a4b90bfbfc59751e1c/c/d472f7b81...   \n",
      "\n",
      "                               PostID      PostedBy  SourceName  \\\n",
      "0  e/ed12adf025b5491da54c4ff2c8c5377a  koenigdublin         NaN   \n",
      "1  e/7f6fb13b5a99449bb9dcbb3f8693be73  ilportalinux         NaN   \n",
      "2  e/624ca9226b6526ebdb69f9b46df482c7    guardianuk         NaN   \n",
      "3  e/2fdf59e075094fe1847137af34eda0f7          nahi  m.ctor.org   \n",
      "4  e/4d8de05f989d43a4b90bfbfc59751e1c       miocaro         NaN   \n",
      "\n",
      "                SourceURL GeoX GeoY            Timestamp  \\\n",
      "0                     NaN   \\N   \\N  2010-08-06 15:06:32   \n",
      "1                     NaN   \\N   \\N  2010-08-06 15:06:32   \n",
      "2                     NaN   \\N   \\N  2010-08-06 14:45:07   \n",
      "3  http://m.ctor.org/f2p/   \\N   \\N  2010-08-06 15:06:32   \n",
      "4                     NaN   \\N   \\N  2010-08-06 15:06:31   \n",
      "\n",
      "                                                Text  NumImg  ImgURL  \\\n",
      "0  В начале 20 века  было противостояние идеологи...     NaN     NaN   \n",
      "1                                     sofferenza? :D     NaN     NaN   \n",
      "2  Reel Review video: Catherine Shoard defends Kn...     NaN     NaN   \n",
      "3                                VMWareじゃなくてVMwareね。     NaN     NaN   \n",
      "4      Anıl havuzdan uzak dur. Sen evde olacaksın :)     NaN     NaN   \n",
      "\n",
      "   NumVideos  VideosURL  \n",
      "0        NaN        NaN  \n",
      "1        NaN        NaN  \n",
      "2        NaN        NaN  \n",
      "3        NaN        NaN  \n",
      "4        NaN        NaN  \n",
      "(509526, 5)\n",
      "                                                  ID Type Name ReservedField  \\\n",
      "0             ID,Type,Name,ReservedField,Description  NaN  NaN           NaN   \n",
      "1  spaceastronautics,user,Space & Astronautics Ne...  NaN  NaN           NaN   \n",
      "2   donpierreorsini,user,Don Pierre ORSINI,ccc72ce0,  NaN  NaN           NaN   \n",
      "3  donrday,user,Don Day,f1c2a383,\"Besides his mai...  NaN  NaN           NaN   \n",
      "4            donrogers,user,Brandon Rogers,fefd06da,  NaN  NaN           NaN   \n",
      "\n",
      "  Description  \n",
      "0         NaN  \n",
      "1         NaN  \n",
      "2         NaN  \n",
      "3         NaN  \n",
      "4         NaN  \n",
      "(19547158, 3)\n",
      "      FollowedID      FollowerID                   Timestamp\n",
      "0      njsinc4el    brendafranzo  2010-08-01 16:21:37.562726\n",
      "1      njsinc4el       praguebob  2010-08-01 16:21:37.565893\n",
      "2  zachhwilliams      hungheroic  2010-08-01 16:21:37.779807\n",
      "3  zachhwilliams      ridwan2906  2010-08-01 16:21:37.780406\n",
      "4  zachhwilliams  nickcodipietro  2010-08-01 16:21:37.780894\n",
      "(798112, 3)\n",
      "             userID                              PostID            Timestamp\n",
      "0           yasinde  e/2d4fcaed2d2a4ac1a36571b66da3f16c  2010-04-28 07:17:43\n",
      "1  socialnewsturkey  e/2d4fcaed2d2a4ac1a36571b66da3f16c  2010-03-02 20:10:02\n",
      "2             janzu  e/2d4fcaed2d2a4ac1a36571b66da3f16c  2010-03-02 19:50:57\n",
      "3        mugecerman  e/2d4fcaed2d2a4ac1a36571b66da3f16c  2010-03-02 19:18:38\n",
      "4           miocaro  e/2d4fcaed2d2a4ac1a36571b66da3f16c  2010-03-02 17:31:31\n",
      "(12450658, 12)\n",
      "                               PostID     PostedBy             SourceName  \\\n",
      "0  e/29af803d670fb8d67692095f3ee623e6    newsroom1  Ottawa Citizen - News   \n",
      "1  e/9c8413a376bec6389be4d46d0812c2bb  mehmetinnet           Mehmetin.Net   \n",
      "2  e/2d658d97842a466a9513f587f85b0e59  mehmetergin           Mehmetin.Net   \n",
      "3  e/b269ab5d56be4e5e90c1954ecc1ef63a       afriki                    NaN   \n",
      "4  e/74f0a50c374a4ad6bddcbcc60c60cad9     hamsafar                    NaN   \n",
      "\n",
      "                                 SourceURL GeoX GeoY            Timestamp  \\\n",
      "0  http://www.ottawacitizen.com/index.html   \\N   \\N  2010-08-02 18:43:10   \n",
      "1                  http://www.mehmetin.net   \\N   \\N  2010-08-02 19:15:52   \n",
      "2                 http://www.mehmetin.net/   \\N   \\N  2010-08-02 19:15:52   \n",
      "3                                      NaN   \\N   \\N  2010-08-02 16:37:57   \n",
      "4                                      NaN   \\N   \\N  2010-08-02 18:54:39   \n",
      "\n",
      "                                                Text  NumImg  \\\n",
      "0  RIM 'will not compromise' BlackBerry security ...     1.0   \n",
      "1  Fethullah Gülen: Referandum siyasî olarak görü...     1.0   \n",
      "2  Fethullah Gülen: Referandum siyasî olarak görü...     1.0   \n",
      "3  Мне тут недавно один дизайнер сказал: «Ну прот...     0.0   \n",
      "4                           عرض سلام و خسته نباشيد:)     0.0   \n",
      "\n",
      "                                              ImgURL  NumVideos VideosURL  \n",
      "0   http://www.ottawacitizen.com/will+compromise+...        0.0       NaN  \n",
      "1   http://www.mehmetin.net/2010/08/fethullah-gul...        0.0       NaN  \n",
      "2   http://www.mehmetin.net/2010/08/fethullah-gul...        0.0       NaN  \n",
      "3                                                NaN        0.0       NaN  \n",
      "4                                                NaN        0.0       NaN  \n"
     ]
    }
   ],
   "source": [
    "# Load Comments\n",
    "comments = pd.read_csv(\"data/filtered_comments.csv\", delimiter=\"\\t\", header=None, names=[\"EntryID\", \"PostID\", \"PostedBy\", \"SourceName\", \"SourceURL\", \"GeoX\", \"GeoY\", \"Timestamp\", \"Text\", \"NumImg\", \"ImgURL\", \"NumVideos\", \"VideosURL\"])\n",
    "\n",
    "# Load Users\n",
    "users = pd.read_csv(\"data/filtered_users.csv\", delimiter=\"|\", header=None, names=[\"ID\", \"Type\", \"Name\", \"ReservedField\", \"Description\"], on_bad_lines='skip')\n",
    "\n",
    "# Load Following\n",
    "following = pd.read_csv(\"data/filtered_following.csv\", delimiter=\"\\t\", header=None, names=[\"FollowedID\", \"FollowerID\", \"Timestamp\"], on_bad_lines='skip')\n",
    "\n",
    "# Load Likes\n",
    "likes = pd.read_csv(\"data/filtered_likes.csv\", delimiter=\"\\t\", header=None, names=[\"userID\", \"PostID\", \"Timestamp\"], on_bad_lines='skip')\n",
    "\n",
    "\n",
    "# Load Entries/Posts\n",
    "entries = pd.read_csv(\"data/filtered_entries.csv\", delimiter=\"\\t\", header=None, names=[\"PostID\", \"PostedBy\", \"SourceName\", \"SourceURL\", \"GeoX\", \"GeoY\", \"Timestamp\", \"Text\", \"NumImg\", \"ImgURL\", \"NumVideos\", \"VideosURL\"], on_bad_lines='skip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd30d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier detection preparation of features for each user\n",
    "\n",
    "\n",
    "\n",
    "# --- Follower Count ---\n",
    "follower_count = following['FollowedID'].value_counts()\n",
    "follower_count.name = 'FollowerCount'\n",
    "\n",
    "# --- Following Count ---\n",
    "following_count = following['FollowerID'].value_counts()\n",
    "following_count.name = 'FollowingCount'\n",
    "\n",
    "# --- Posts Created ---\n",
    "posts_created = entries['PostedBy'].value_counts()\n",
    "posts_created.name = 'PostsCreated'\n",
    "\n",
    "# --- Likes Received per Post ---\n",
    "likes_per_post = likes.groupby('PostID').size().rename('LikesCount')\n",
    "posts_with_likes = entries.merge(likes_per_post, on='PostID', how='left')\n",
    "posts_with_likes['LikesCount'] = posts_with_likes['LikesCount'].fillna(0)\n",
    "avg_likes_received = posts_with_likes.groupby('PostedBy')['LikesCount'].mean()\n",
    "avg_likes_received.name = 'AvgLikesReceived'\n",
    "\n",
    "# --- Likes Given ---\n",
    "likes_given = likes['userID'].value_counts()\n",
    "likes_given.name = 'LikesGiven'\n",
    "\n",
    "# --- Comments Received per Post ---\n",
    "comments_per_post = comments.groupby('PostID').size().rename('CommentsCount')\n",
    "posts_with_comments = entries.merge(comments_per_post, on='PostID', how='left')\n",
    "posts_with_comments['CommentsCount'] = posts_with_comments['CommentsCount'].fillna(0)\n",
    "avg_comments_received = posts_with_comments.groupby('PostedBy')['CommentsCount'].mean()\n",
    "avg_comments_received.name = 'AvgCommentsReceived'\n",
    "\n",
    "# --- Comments Given ---\n",
    "comments_given = comments['PostedBy'].value_counts()\n",
    "comments_given.name = 'CommentsGiven'\n",
    "\n",
    "feature_list = [\n",
    "    follower_count,\n",
    "    following_count,\n",
    "    posts_created,\n",
    "    avg_likes_received,\n",
    "    likes_given,\n",
    "    avg_comments_received,\n",
    "    comments_given\n",
    "]\n",
    "anomaly_user_df = pd.concat(feature_list, axis=1).fillna(0)\n",
    "anomaly_user_df.index.name = 'UserID'\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaled_features = scaler.fit_transform(anomaly_user_df)\n",
    "\n",
    "scaled_anomaly_df = pd.DataFrame(scaled_features,\n",
    "                                 index=anomaly_user_df.index,\n",
    "                                 columns=anomaly_user_df.columns)\n",
    "\n",
    "\n",
    "print(\"\\n--- Verification: Check Mean and Standard Deviation of Scaled Data ---\")\n",
    "print(scaled_anomaly_df.describe().loc[['mean', 'std']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c3e71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier detection using different algorithms:\n",
    "\n",
    "# This hyperparameter defines the percentage of data points you expect to be outliers.\n",
    "# It's a critical parameter to tune based on your domain knowledge.\n",
    "CONTAMINATION_RATE = 0.05 \n",
    "\n",
    "# Dictionary to store the results from each algorithm\n",
    "outlier_results = {}\n",
    "\n",
    "## 1. Statistical-based Approach: Multivariate Gaussian\n",
    "print(\"1. Running Multivariate Gaussian (Elliptic Envelope)...\")\n",
    "# This method assumes the regular data comes from a Gaussian distribution and finds\n",
    "# points that have a low probability of belonging to it (high Mahalanobis distance).\n",
    "model = EllipticEnvelope(contamination=CONTAMINATION_RATE,support_fraction=0.9, random_state=42)\n",
    "predictions = model.fit_predict(scaled_anomaly_df)\n",
    "outliers_indices = np.where(predictions == -1)[0]\n",
    "outlier_results['MultivariateGaussian'] = scaled_anomaly_df.index[outliers_indices].tolist()\n",
    "\n",
    "\n",
    "\n",
    "## 2. Clustering-based Approach: MiniBatchKMeans\n",
    "print(\"2. Running Clustering-based (MiniBatchKMeans)...\")\n",
    "# MiniBatchKMeans is much more scalable than DBSCAN for large datasets.\n",
    "# We identify outliers as points with the largest distance to their cluster centroid.\n",
    "n_clusters = 20 # The number of clusters is a hyperparameter to tune\n",
    "model = MiniBatchKMeans(n_clusters=n_clusters, random_state=42, n_init='auto')\n",
    "model.fit(scaled_anomaly_df)\n",
    "\n",
    "# Calculate the distance of each point to its assigned cluster's center\n",
    "distances_to_center = np.linalg.norm(scaled_anomaly_df - model.cluster_centers_[model.labels_], axis=1)\n",
    "\n",
    "# Flag the top % of points with the largest distances as outliers\n",
    "threshold = np.quantile(distances_to_center, 1 - CONTAMINATION_RATE)\n",
    "outliers_indices = np.where(distances_to_center > threshold)[0]\n",
    "outlier_results['MiniBatchKMeans'] = scaled_anomaly_df.index[outliers_indices].tolist()\n",
    "\n",
    "## 3. Distance-based Approach: Largest Distances\n",
    "print(\"3. Running Distance-based (k-NN)...\")\n",
    "# This identifies outliers as points with the largest distance to their k-th nearest neighbor.\n",
    "# We calculate this distance for every point and then flag the top N% as outliers.\n",
    "k = 5\n",
    "model = NearestNeighbors(n_neighbors=k)\n",
    "model.fit(scaled_anomaly_df)\n",
    "distances, _ = model.kneighbors(scaled_anomaly_df)\n",
    "kth_distances = distances[:, k-1] # Distance to the k-th neighbor\n",
    "threshold = np.quantile(kth_distances, 1 - CONTAMINATION_RATE)\n",
    "outliers_indices = np.where(kth_distances > threshold)[0]\n",
    "outlier_results['kNN_Distance'] = scaled_anomaly_df.index[outliers_indices].tolist()\n",
    "\n",
    "## 4. Density-based Approach: LOF\n",
    "print(\"4. Running Density-based (LOF)...\")\n",
    "# Local Outlier Factor (LOF) measures the local density deviation of a data point\n",
    "# with respect to its neighbors. Outliers are points in much sparser regions than their neighbors.\n",
    "model = LocalOutlierFactor(n_neighbors=20, contamination=CONTAMINATION_RATE, novelty=False)\n",
    "predictions = model.fit_predict(scaled_anomaly_df)\n",
    "outliers_indices = np.where(predictions == -1)[0]\n",
    "outlier_results['LOF'] = scaled_anomaly_df.index[outliers_indices].tolist()\n",
    "\n",
    "## 5. Isolation-based Approach: iForest\n",
    "print(\"5. Running Isolation-based (Isolation Forest)...\")\n",
    "# Isolation Forest isolates observations by randomly selecting a feature and then\n",
    "# randomly selecting a split value. Anomalies are easier to isolate and thus have shorter path lengths.\n",
    "model = IsolationForest(contamination=CONTAMINATION_RATE, random_state=42)\n",
    "predictions = model.fit_predict(scaled_anomaly_df)\n",
    "outliers_indices = np.where(predictions == -1)[0]\n",
    "outlier_results['IsolationForest'] = scaled_anomaly_df.index[outliers_indices].tolist()\n",
    "\n",
    "## 6. One-Class SVM\n",
    "print(\"6. Running One-Class SVM...\")\n",
    "# OCSVM learns a decision boundary that encompasses the majority of the data.\n",
    "# Points falling outside this boundary are considered outliers.\n",
    "model = OneClassSVM(nu=CONTAMINATION_RATE, kernel=\"rbf\", gamma=\"auto\")\n",
    "predictions = model.fit_predict(scaled_anomaly_df)\n",
    "outliers_indices = np.where(predictions == -1)[0]\n",
    "outlier_results['OneClassSVM'] = scaled_anomaly_df.index[outliers_indices].tolist()\n",
    "\n",
    "## 7. Reconstruction Error Approach: PCA\n",
    "print(\"7. Running Reconstruction Error (PCA)...\")\n",
    "# This approach uses PCA to project data into a lower-dimensional space and then\n",
    "# projects it back. Outliers, which don't fit the main data patterns, will have a\n",
    "# high reconstruction error.\n",
    "n_components = 5 # Should be less than the number of features\n",
    "model = PCA(n_components=n_components)\n",
    "transformed = model.fit_transform(scaled_anomaly_df)\n",
    "reconstructed = model.inverse_transform(transformed)\n",
    "reconstruction_error = np.linalg.norm(scaled_anomaly_df - reconstructed, axis=1)\n",
    "threshold = np.quantile(reconstruction_error, 1 - CONTAMINATION_RATE)\n",
    "outliers_indices = np.where(reconstruction_error > threshold)[0]\n",
    "outlier_results['PCA_Reconstruction'] = scaled_anomaly_df.index[outliers_indices].tolist()\n",
    "\n",
    "\n",
    "# --- Aggregate and Summarize Results ---\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"--- Anomaly Detection Summary ---\")\n",
    "\n",
    "# Flatten the list of all outliers found\n",
    "all_outliers = [user_id for method_outliers in outlier_results.values() for user_id in method_outliers]\n",
    "\n",
    "# Count how many times each user was flagged as an outlier\n",
    "outlier_counts = Counter(all_outliers)\n",
    "\n",
    "# Create a summary DataFrame\n",
    "summary_df = pd.DataFrame(outlier_counts.items(), columns=['UserID', 'Anomaly_Count'])\n",
    "summary_df = summary_df.sort_values(by='Anomaly_Count', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(f\"\\nTotal unique users flagged as outliers: {len(summary_df)}\")\n",
    "print(\"\\nTop 20 most anomalous users:\")\n",
    "print(summary_df.head(20))\n",
    "\n",
    "# You can also create a detailed DataFrame showing which algorithm flagged which user\n",
    "detailed_summary_df = scaled_anomaly_df.copy()\n",
    "for method, outliers in outlier_results.items():\n",
    "    detailed_summary_df[method] = detailed_summary_df.index.isin(outliers)\n",
    "\n",
    "detailed_summary_df['Anomaly_Count'] = detailed_summary_df.iloc[:, -len(outlier_results):].sum(axis=1)\n",
    "detailed_summary_df = detailed_summary_df.sort_values(by='Anomaly_Count', ascending=False)\n",
    "\n",
    "print(\"\\nDetailed breakdown for users flagged by 3 or more algorithms:\")\n",
    "print(detailed_summary_df[detailed_summary_df['Anomaly_Count'] >= 3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
