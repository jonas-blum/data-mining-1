{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a6c67e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import community as community_louvain\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ca39d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Comments\n",
    "comments = pd.read_csv(\"data/filtered_comments.csv\")\n",
    "\n",
    "# Load Users\n",
    "users = pd.read_csv(\"data/filtered_users.csv\")\n",
    "\n",
    "# Load Following\n",
    "following = pd.read_csv(\"data/filtered_following.csv\")\n",
    "\n",
    "# Load Likes\n",
    "likes = pd.read_csv(\"data/filtered_likes.csv\")\n",
    "\n",
    "# Load Entries/Posts\n",
    "entries = pd.read_csv(\"data/filtered_entries.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1697ff2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Graph created successfully.\n",
      "-> Nodes (Users): 484251\n",
      "-> Edges (Connections): 18477145\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# show a graph of people following other people\n",
    "\n",
    "G = nx.from_pandas_edgelist(following, source='FollowerID', target='FollowedID', create_using=nx.DiGraph())\n",
    "print(f\"-> Graph created successfully.\")\n",
    "print(f\"-> Nodes (Users): {G.number_of_nodes()}\")\n",
    "print(f\"-> Edges (Connections): {G.number_of_edges()}\")\n",
    "print(\"-\" * 30)\n",
    "plt.figure(figsize=(10,10))\n",
    "pos = nx.spring_layout(G, k=0.1)\n",
    "nx.draw(G, pos, node_size=10, alpha=0.3, arrows=False)\n",
    "plt.title('Follower Network')\n",
    "plt.savefig('results/follower_network.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# --- 2. Detect Communities with Louvain Algorithm (from your existing code) ---\n",
    "print(\"Step 2: Running the Louvain algorithm...\")\n",
    "partition = community_louvain.best_partition(G)\n",
    "print(\"-> Community detection complete.\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# --- 3. Analyze and Process the Results (from your existing code) ---\n",
    "print(\"Step 3: Analyzing community results...\")\n",
    "num_communities = len(set(partition.values()))\n",
    "print(f\"-> Discovered {num_communities} distinct communities.\")\n",
    "partition_df = pd.DataFrame(list(partition.items()), columns=['ID', 'CommunityID'])\n",
    "community_sizes = partition_df['CommunityID'].value_counts().reset_index()\n",
    "community_sizes.columns = ['CommunityID', 'NumberOfMembers']\n",
    "print(\"\\nTop 10 Largest Social Circles:\")\n",
    "print(community_sizes.head(10).to_string(index=False))\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# --- 4. Merge and Save Results (from your existing code) ---\n",
    "print(\"Step 4: Merging and saving results...\")\n",
    "users_with_communities = pd.merge(users, partition_df, on='ID', how='inner')\n",
    "output_filepath = \"results/users_with_communities.csv\"\n",
    "users_with_communities.to_csv(output_filepath, index=False, encoding='utf-8')\n",
    "print(f\"-> Successfully saved results to '{output_filepath}'\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# --- 5. Display a Sample from the Largest Community (from your existing code) ---\n",
    "if not community_sizes.empty:\n",
    "    largest_community_id = community_sizes.iloc[0]['CommunityID']\n",
    "    print(f\"Step 5: Sample of users from the largest community (ID: {largest_community_id}):\")\n",
    "    largest_community_members = users_with_communities[\n",
    "        users_with_communities['CommunityID'] == largest_community_id\n",
    "    ]\n",
    "    print(largest_community_members[['ID', 'Name', 'CommunityID']].head(15).to_string(index=False))\n",
    "else:\n",
    "    print(\"No communities were found to display a sample.\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "\n",
    "# --- 6. NEW: Plot Degree Distribution ---\n",
    "print(\"Step 6: Generating Degree Distribution Plot...\")\n",
    "# Get the degree (number of connections) for each node\n",
    "degrees = [G.degree(n) for n in G.nodes()]\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(12, 7))\n",
    "plt.hist(degrees, bins=100, log=True, color='skyblue', ec='black')\n",
    "plt.title('Degree Distribution of the Social Network (Log Scale)', fontsize=16)\n",
    "plt.xlabel('Degree (Number of Connections)', fontsize=12)\n",
    "plt.ylabel('Number of Users (Log Scale)', fontsize=12)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Save the plot to a file\n",
    "degree_plot_path = 'results/degree_distribution.png'\n",
    "plt.savefig(degree_plot_path)\n",
    "print(f\"-> Degree distribution plot saved to '{degree_plot_path}'\")\n",
    "plt.show() # Display the plot in the notebook\n",
    "print(\"-\" * 30)\n",
    "\n",
    "\n",
    "# --- 7. NEW: Visualize the Largest Community ---\n",
    "print(f\"Step 7: Visualizing the largest community (ID: {largest_community_id})...\")\n",
    "\n",
    "# Extract nodes that belong to the largest community\n",
    "nodes_in_community = [\n",
    "    n for n, c_id in partition.items() if c_id == largest_community_id\n",
    "]\n",
    "\n",
    "# Create a subgraph containing only the nodes and edges from that community\n",
    "subgraph = G.subgraph(nodes_in_community)\n",
    "print(f\"-> Largest community has {subgraph.number_of_nodes()} members.\")\n",
    "\n",
    "# For clarity, we'll only draw a sample if the community is too large\n",
    "if subgraph.number_of_nodes() > 200:\n",
    "    print(\"-> Community is too large to draw clearly. A random sample of 200 nodes will be visualized.\")\n",
    "    # Take a random sample of nodes from the subgraph\n",
    "    sampled_nodes = pd.Series(list(subgraph.nodes())).sample(200, random_state=42).tolist()\n",
    "    # Create the final subgraph for visualization from the sample\n",
    "    vis_subgraph = subgraph.subgraph(sampled_nodes)\n",
    "else:\n",
    "    vis_subgraph = subgraph\n",
    "\n",
    "# Draw the graph\n",
    "plt.figure(figsize=(15, 15))\n",
    "# Use a spring layout for a more organic look\n",
    "pos = nx.spring_layout(vis_subgraph, seed=42, k=0.15)\n",
    "\n",
    "# Draw nodes and edges\n",
    "nx.draw_networkx_nodes(vis_subgraph, pos, node_size=50, node_color='lightgreen', alpha=0.9)\n",
    "nx.draw_networkx_edges(vis_subgraph, pos, width=0.5, alpha=0.3, edge_color='gray')\n",
    "\n",
    "plt.title(f'Visualization of Largest Social Circle (Community ID: {largest_community_id})', fontsize=20)\n",
    "plt.axis('off') # Hide the axes\n",
    "\n",
    "# Save the visualization to a file\n",
    "community_plot_path = 'results/largest_community_graph.png'\n",
    "plt.savefig(community_plot_path)\n",
    "print(f\"-> Community graph saved to '{community_plot_path}'\")\n",
    "plt.show() # Display the plot in the notebook\n",
    "print(\"-\" * 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51d8032",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_N_COMMUNITIES = 10\n",
    "\n",
    "def print_stats(data_series, description):\n",
    "    \"\"\"Calculates and prints key statistics for a pandas Series.\"\"\"\n",
    "    print(f\"--- {description} ---\")\n",
    "    if data_series.empty:\n",
    "        print(\"No data available to calculate statistics.\")\n",
    "    else:\n",
    "        print(f\"Average: {data_series.mean():.2f}\")\n",
    "        print(f\"Median: {data_series.median():.2f}\")\n",
    "        print(f\"Standard Deviation: {data_series.std():.2f}\")\n",
    "        print(f\"Min: {data_series.min()}\")\n",
    "        print(f\"Max: {data_series.max()}\")\n",
    "    print(\"-\" * (len(description) + 8) + \"\\n\")\n",
    "\n",
    "top_communities = users_with_communities['CommunityID'].value_counts().nlargest(TOP_N_COMMUNITIES).index\n",
    "\n",
    "for community_id in top_communities:\n",
    "    print(f\"=============================================\")\n",
    "    print(f\"      ANALYZING COMMUNITY ID: {community_id}\")\n",
    "    print(f\"=============================================\\n\")\n",
    "\n",
    "    # 1. Get all user IDs for the current community\n",
    "    community_members = users_with_communities[users_with_communities['CommunityID'] == community_id]['ID']\n",
    "\n",
    "    # 2. Filter the main dataframes for members of this community\n",
    "    following_c = following[following['FollowerID'].isin(community_members) | following['FollowedID'].isin(community_members)]\n",
    "    entries_c = entries[entries['PostedBy'].isin(community_members)]\n",
    "    likes_c = likes[likes['userID'].isin(community_members)]\n",
    "    comments_c = comments[comments['PostedBy'].isin(community_members)]\n",
    "\n",
    "    # --- Follower Count ---\n",
    "    follower_count = following_c[following_c['FollowedID'].isin(community_members)]['FollowedID'].value_counts()\n",
    "    print_stats(follower_count, f\"Follower Count (Community {community_id})\")\n",
    "\n",
    "    # --- Following Count ---\n",
    "    following_count = following_c[following_c['FollowerID'].isin(community_members)]['FollowerID'].value_counts()\n",
    "    print_stats(following_count, f\"Following Count (Community {community_id})\")\n",
    "\n",
    "    # --- Posts Created ---\n",
    "    posts_created = entries_c['PostedBy'].value_counts()\n",
    "    print_stats(posts_created, f\"Posts Created (Community {community_id})\")\n",
    "\n",
    "    # --- Likes Received on Average per Post ---\n",
    "    if not entries_c.empty:\n",
    "        likes_per_post = likes.groupby('PostID').size().rename('LikesCount')\n",
    "        posts_with_likes = entries_c.merge(likes_per_post, on='PostID', how='left').fillna(0)\n",
    "        avg_likes_received = posts_with_likes.groupby('PostedBy')['LikesCount'].mean()\n",
    "        print_stats(avg_likes_received, f\"Avg. Likes Received per Post (Community {community_id})\")\n",
    "    else:\n",
    "        print_stats(pd.Series(), f\"Avg. Likes Received per Post (Community {community_id})\")\n",
    "\n",
    "\n",
    "    # --- Likes Given ---\n",
    "    likes_given = likes_c['userID'].value_counts()\n",
    "    print_stats(likes_given, f\"Likes Given (Community {community_id})\")\n",
    "\n",
    "    # --- Comments Received on Average per Post ---\n",
    "    if not entries_c.empty:\n",
    "        comments_per_post = comments.groupby('PostID').size().rename('CommentsCount')\n",
    "        posts_with_comments = entries_c.merge(comments_per_post, on='PostID', how='left').fillna(0)\n",
    "        avg_comments_received = posts_with_comments.groupby('PostedBy')['CommentsCount'].mean()\n",
    "        print_stats(avg_comments_received, f\"Comments Received per Post (Community {community_id})\")\n",
    "    else:\n",
    "        print_stats(pd.Series(), f\"Comments Received per Post (Community {community_id})\")\n",
    "\n",
    "    # --- Comments Given ---\n",
    "    comments_given = comments_c['PostedBy'].value_counts()\n",
    "    print_stats(comments_given, f\"Comments Given (Community {community_id})\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
